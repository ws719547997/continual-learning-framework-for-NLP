# continual-learning-framework-for-NLP
## 前言

关于这个持续学习框架，我暂时希望它能拥有如下的特点，这是我在科研和工作中总结出来的.

### dataloader
这个部分的关注点实际在任务上，它的作用范围应该被清晰的限制在对任务的处理、整理、保存和输出。
因此再来考虑一下需求：
- 方便的选择不同的数据集，不同的任务构成一个任务序列；
目前已经实现，在具体的实现中，每个任务的输入格式和输出BERT后需要的top网络可能不同，因此如何去决定这些设定呢？一种想法是设定专门对应的参数，一种是程序根据任务做对应的设定。专门设定会清晰很多但是很麻烦，因此目前的想法是在arge里设定默认值或者缺省值，如果需要，可以在每个任务中设定对应的参数。
但是！！！目前的实验环境仅仅支持对token向量化的任务，超长文本对每个句子向量暂时还不能支持。
- 对任务序列中任务的数量、顺序可以方便的编排与控制，方便打乱序列进行多次实验；
在这种情况下，taskmanager中的元素应该少一点，给打乱顺序带来便利。
- 由于不同种类的任务可能对应不同的tokenizer，希望能在各种预训练语言模型之间切换；
这也是一个参数和模型设定的参数有关，但在任务之间应该保持统一。所以会根据任务类型+模型的选择来确定tokenizer
- 我还希望能够支持多卡训练；
在第一版中不会支持，先从3060-16G换到4090-24G试试看。
- 希望能够将数据集的相关信息载入日志中；
确实应该选择一个计量的框架，能把各种信息，起码说是能放在一个文件夹里记录下来吧。之前的话，训练日志整理起来真的听蛋疼的。
- 希望任务信息同样能够存储在dataloader中，方便在eval时选择合适的评价指标；
确实，评价指标也要有专门的设定呀，哭。
-暂时不考虑预训练任务，或者其实也可以考虑？其实是tokenizer和对应的top变化了

### 度量
对于度量的重要性是我在工作中体会到的，正如鲁迅所说：“你无法度量，也就无法改进。” 无法度量给我在工作中带来了极致蛋碎的体验。

因此我想在代码重构之初，就将度量纳入考量，其中有几个点：
- 训练过程中模型在dev和test上的测试指标
这个东西是不是可以用tensorborad呀！
- 训练过程中时间、GPU利用率和显存
写了一个类现在能实现了，可能在刚运行模型的时候会比较关注这个指标
- 关于数据集的信息，比如有多少数据
这个教给dataloader输出，已经实现了
- 最后能有详细的评测指标，且可以自己设定一些主流的度量方法
- 希望能看到被错误分类的样本
- 目前的话其实还掌握了py-spy能做一些性能分析。

### 模型
是说希望能够支持pretrain和fineturn（或许还有prompt？）这样的话 我先试试把ptm和top的网络分离开；top的话，会根据每个任务，有所区别：
传入的应该是一个ModelList，输入都是ptm随后一层的向量，sequence len * embedding。输出就是根据任务了，输入的话，都是用tokenizer统一起来。
借鉴了UER，还要兼容transformers，还读到一个Adapter-transformers，应该研究一下怎么实现的。

其实模型是需要一个骨架，然后选择合适的模块把他们拼接起来，但是这个拼接其实挺麻烦的，之前的做法是直接写死在代码里，作为一个network直接进行选择，但是现在的话其实还很不明朗。
这样的话确实有很多细节难以看到，而且调参的时候也挺麻烦的，不如还是弄一堆文件好了。

——————————
update 2023.3.1
——————————

对于dataloader类，我的想法是兼容huggingface的datasets库，把数据集传上去，然后借由简单的接口去操作，方便获取和处理。
之后对于每个实验的配置，期初我的想法就是弄一个任务序列管理器，去控制各种参数，然后用for循环去执行任务，但是就显得比较蠢，把简单的东西给复杂化了。
于是在新的架构中我想应该将参数完全的配置好，甚至可以在shell脚本中写任务序列的执行逻辑，这样框架更加简洁，由此产生的另一个问题就是评估。这个怎么去实现我还没有好的想法。

experiment setting(including: model,approach,tasklist,optimizer,loss,scheduler)

tasklist(including: datasets, epochs, batch size, task type,eval...)

然后初始化实验设定，把各种东西咔咔咔弄出来，然后开始循环，每个tasklist开始咔咔巡行，参数全部交给approach，训练起来了.
这其中的一个问题就是，任务不同，在BERT里面对应的top是不同的，那么loss也不一样
